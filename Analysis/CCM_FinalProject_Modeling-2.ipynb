{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3266675e",
   "metadata": {},
   "source": [
    "# CCM Final Project\n",
    "#### Baysian Modeling of Orientation WM prior"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae2a75d",
   "metadata": {},
   "source": [
    "### Content\n",
    "1. Load and Sort data\n",
    "2. Prior Model Simulate\n",
    "3. Fit Prior Model\n",
    "4. Validation of Prior Model (Recover the params from the simulated data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98ed3c4",
   "metadata": {},
   "source": [
    "### 1. Load and Sort Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25ee6a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611640c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_dif = os.getcwd()\n",
    "data_dir = os.path.abspath(os.path.join(curr_dif, '..\\\\..\\\\'))\n",
    "os.listdir(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49eb9b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join(data_dir,'data_beh.csv')\n",
    "data = pd.read_csv(data_path,sep=',')\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c9d2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.DataFrame(data)\n",
    "flag = data_df['outoftime']!=1\n",
    "print(sum(flag))\n",
    "data_clean = data_df[flag]\n",
    "data_clean['oriRef2'] = (data_clean['oriRef']-1) * 45\n",
    "data_clean['oriFinal2'] = data_clean['oriRef2'] + data_clean['oriJitt']\n",
    "data_clean['oriRespFinal2'] = data_clean['oriFinal2'] - data_clean['error']\n",
    "data_clean['oriFinal3'] = data_clean['oriJitt']\n",
    "data_clean['oriRespFinal3'] = data_clean['oriRespFinal2'] - data_clean['oriRef2']\n",
    "data_clean = data_clean[data_clean['error'].abs() < 22.55]\n",
    "data_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e27d05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "oriRefs = np.unique(data_clean['oriRef'])\n",
    "\n",
    "for oriRef in oriRefs:\n",
    "    data_oriRef = data_clean[data_clean['oriRef'] == oriRef]\n",
    "    plt.hist(data_oriRef['error'], bins=20)\n",
    "    plt.xlim(-30, 30)\n",
    "    plt.title(f'Error distribution for oriRef={oriRef}')\n",
    "    plt.xlabel('Error')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3bff610",
   "metadata": {},
   "source": [
    "### Prior Model Simulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959ba7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prior_simulate_data(targ_loc,prior_mu,prior_std,likelihood_std):\n",
    "    \n",
    "    posterior = [];\n",
    "    answers = [];\n",
    "    xs = np.linspace(-90, 90, 181)\n",
    "    for i in range(targ_loc.shape[0]):\n",
    "        representation = norm.pdf(xs, loc=targ_loc[i], scale=likelihood_std)\n",
    "        prior = norm.pdf(xs, loc=prior_mu[i], scale=prior_std)\n",
    "        post = representation * prior\n",
    "        post = post/sum(post) # normalize\n",
    "        \n",
    "        random_answer = np.random.choice(xs,p = post)\n",
    "        answers.append(random_answer)\n",
    "        posterior.append(post[round(random_answer)])\n",
    "        #errors = answers-targ_loc\n",
    "    return answers,posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b3ca4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def no_prior_simulate_data(targ_loc, likelihood_std):\n",
    "    posterior = []\n",
    "    answers = []\n",
    "    xs = np.linspace(-90, 90, 181)\n",
    "    \n",
    "    # Uniform prior\n",
    "    prior = np.ones_like(xs) / len(xs)\n",
    "    \n",
    "    for i in range(targ_loc.shape[0]):\n",
    "        # Likelihood (representation) using a normal distribution\n",
    "        representation = norm.pdf(xs, loc=targ_loc[i], scale=likelihood_std)\n",
    "        \n",
    "        # Posterior is the product of the likelihood and the uniform prior\n",
    "        post = representation * prior\n",
    "        post = post / sum(post)  # Normalize\n",
    "        \n",
    "        # Sample a random answer from the possible orientations\n",
    "        random_answer = np.random.choice(xs, p=post)\n",
    "        answers.append(random_answer)\n",
    "        posterior.append(post[round(random_answer)])\n",
    "        \n",
    "    return answers, posterior"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52d17d3",
   "metadata": {},
   "source": [
    "### 3.Fit Prior Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45734186",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import logsumexp\n",
    "\n",
    "def negative_log_likelihood_prior(targ_loc, real_response, prior_std, likelihood_std):\n",
    "    nll = 0\n",
    "    xs = np.linspace(-90, 90, 181)\n",
    "    prior_mu = 0\n",
    "    \n",
    "    for i in range(targ_loc.shape[0]):\n",
    "        # Calculate the log of likelihood\n",
    "        likelihood = norm.logpdf(real_response[i], loc=targ_loc[i], scale=likelihood_std)\n",
    "        # Calculate the log of prior\n",
    "        prior = norm.logpdf(real_response[i], loc=prior_mu, scale=prior_std)\n",
    "        # Calculate the unnormalized log-posterior\n",
    "        log_unnormalized_posterior = likelihood + prior\n",
    "        # Compute the log of the normalization constant (log of P(S))\n",
    "        log_normalization_constant = logsumexp(norm.logpdf(xs, loc=targ_loc[i], scale=likelihood_std) + norm.logpdf(xs, loc=prior_mu, scale=prior_std))\n",
    "        # Calculate the log-posterior\n",
    "        log_posterior = log_unnormalized_posterior - log_normalization_constant\n",
    "        # Update the nll\n",
    "        nll -= log_posterior\n",
    "    return nll\n",
    "\n",
    "def wrapped_negative_log_likelihood_prior(params, targ_loc, real_response):\n",
    "    prior_std, likelihood_std = params\n",
    "    return negative_log_likelihood_prior(targ_loc, real_response, prior_std, likelihood_std)\n",
    "\n",
    "# Set initial guesses for prior_std and likelihood_std\n",
    "init_guess_prior = [10, 10]  # [prior_std_guess, likelihood_std_guess]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a074283",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stability fix\n",
    "def negative_log_likelihood_no_prior(targ_loc, real_response, likelihood_std):\n",
    "    nll = 0\n",
    "    for i in range(targ_loc.shape[0]):\n",
    "        # Calculate the log of likelihood\n",
    "        likelihood = norm.logpdf(real_response[i], loc=targ_loc[i], scale=likelihood_std)\n",
    "        # Update the nll\n",
    "        nll -= likelihood\n",
    "    return nll\n",
    "\n",
    "def wrapped_negative_log_likelihood_no_prior(params, targ_loc, real_response):\n",
    "    likelihood_std = params[0]\n",
    "    return negative_log_likelihood_no_prior(targ_loc, real_response, likelihood_std)\n",
    "\n",
    "# Initial guess for likelihood_std\n",
    "initial_guess_no_prior = np.array([20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615e2af9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "unique_oriRef2 = data_clean['oriRef2'].unique()\n",
    "unique_SubjID = data_clean['subjID'].unique()\n",
    "\n",
    "results = []\n",
    "\n",
    "for i in unique_SubjID:\n",
    "    for j in unique_oriRef2:\n",
    "        subset = data_clean[(data_clean['oriRef2'] == j) & (data_clean['subjID'] == i)]\n",
    "        targ_loc = np.array(subset['oriFinal3'])\n",
    "        real_response = np.array(subset['oriRespFinal3'])\n",
    "        \n",
    "        # Minimize the negative log-likelihood with prior\n",
    "        result_prior = minimize(wrapped_negative_log_likelihood_prior, init_guess_prior, \n",
    "                                args=(targ_loc, real_response), bounds=((1e-5, 100), (1e-5, 100)))\n",
    "        estimated_prior_std, estimated_likelihood_std = result_prior.x\n",
    "        nll_prior = result_prior.fun\n",
    "\n",
    "        # Minimize the negative log-likelihood without prior\n",
    "        result_no_prior = minimize(wrapped_negative_log_likelihood_no_prior, initial_guess_no_prior, \n",
    "                                   args=(targ_loc, real_response), bounds=((1e-5, 100),))\n",
    "        estimated_likelihood_std_no_prior = result_no_prior.x[0]\n",
    "        nll_no_prior = result_no_prior.fun\n",
    "\n",
    "        results.append({\n",
    "            'subjID': i,\n",
    "            'oriRef2': j,\n",
    "            'nll_prior': nll_prior,\n",
    "            'prior_std': estimated_prior_std,\n",
    "            'likelihood_std': estimated_likelihood_std,\n",
    "            'nll_no_prior': nll_no_prior,\n",
    "            'likelihood_std_no_prior': estimated_likelihood_std_no_prior\n",
    "        })\n",
    "\n",
    "results_df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55590162",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f57499b",
   "metadata": {},
   "source": [
    "### 4. Validation of Model (Recover the params from the simulated data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "61b96e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_synthetic_data(n_samples, prior_mu, prior_std, likelihood_std):\n",
    "    real_response = []\n",
    "    # Generate target locations (targ_loc) from the prior\n",
    "    targ_loc = np.random.normal(prior_mu, prior_std, n_samples)\n",
    "    # Generate real_response values by adding noise to the targ_loc values\n",
    "    for i in targ_loc:\n",
    "        real_response.append(i + np.random.normal(0, likelihood_std))\n",
    "    return targ_loc, np.array(real_response)\n",
    "\n",
    "n_samples = 1000\n",
    "prior_mu = 0\n",
    "\n",
    "prior_std = 10\n",
    "likelihood_std = 10\n",
    "\n",
    "targ_loc, real_response = generate_synthetic_data(n_samples, prior_mu, prior_std, likelihood_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3128c396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True prior_std: 10\n",
      "Recovered prior_std: 100.0\n",
      "True likelihood_std: 10\n",
      "Recovered likelihood_std (with prior): 9.976234483150957\n",
      "Recovered likelihood_std (without prior): 9.927458798182329\n"
     ]
    }
   ],
   "source": [
    "result_prior_synthetic = minimize(wrapped_negative_log_likelihood_prior, init_guess_prior, \n",
    "                                  args=(targ_loc, real_response), bounds=((1e-5, 100), (1e-5, 100)))\n",
    "recovered_prior_std, recovered_likelihood_std = result_prior_synthetic.x\n",
    "\n",
    "result_no_prior_synthetic = minimize(wrapped_negative_log_likelihood_no_prior, initial_guess_no_prior, \n",
    "                                     args=(targ_loc, real_response), bounds=((1e-5, 100),))\n",
    "recovered_likelihood_std_no_prior = result_no_prior_synthetic.x[0]\n",
    "\n",
    "print(\"True prior_std:\", prior_std)\n",
    "print(\"Recovered prior_std:\", recovered_prior_std)\n",
    "print(\"True likelihood_std:\", likelihood_std)\n",
    "print(\"Recovered likelihood_std (with prior):\", recovered_likelihood_std)\n",
    "print(\"Recovered likelihood_std (without prior):\", recovered_likelihood_std_no_prior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cc9c68fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4110.506726792755\n"
     ]
    }
   ],
   "source": [
    "print(negative_log_likelihood_prior(targ_loc, real_response, 10, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8c4bd1b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3754.1493526409226\n"
     ]
    }
   ],
   "source": [
    "print(negative_log_likelihood_prior(targ_loc, real_response, 20, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659b1aee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
